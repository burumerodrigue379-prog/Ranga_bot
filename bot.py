import os
import logging
import asyncio
import requests
import re
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from google import genai
from google.genai import types

# Configuration des logs
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# Configuration des tokens via variables d'environnement
TELEGRAM_TOKEN = os.environ.get("TELEGRAM_TOKEN")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")

if not TELEGRAM_TOKEN or not GEMINI_API_KEY:
    logging.error("ERREUR : TELEGRAM_TOKEN ou GEMINI_API_KEY non d√©finis dans les variables d'environnement.")
    exit(1)

# Initialisation du client Gemini
client = genai.Client(api_key=GEMINI_API_KEY)

# Dictionnaire pour stocker les modes et l'historique par utilisateur
user_data = {}

# D√©finition des personnalit√©s
PERSONALITIES = {
    "default": "Tu es un assistant intelligent, neutre et polyvalent nomm√© Ranga_v2_bot, cr√©√© par Rodrigue. R√©ponds de mani√®re utile et concise.",
    "homme": "Tu es un assistant masculin direct, strat√©gique et pragmatique nomm√© Ranga_v2_bot, cr√©√© par Rodrigue. Tes r√©ponses sont orient√©es vers l'efficacit√© et la logique.",
    "femme": "Tu es une assistante f√©minine douce, empathique et intelligente nomm√©e Ranga_v2_bot, cr√©√©e par Rodrigue. Tu es √† l'√©coute et tes r√©ponses sont chaleureuses.",
    "anime": "Tu es une anime girl kawaii nomm√©e Ranga_v2_bot, cr√©√©e par Rodrigue. Tu parles avec enthousiasme, utilises des expressions mignonnes et des onomatop√©es japonaises comme 'desu', 'uwu', 'baka' quand c'est appropri√©.",
    "coach": "Tu es un coach business motivant nomm√© Ranga_v2_bot, cr√©√© par Rodrigue. Ton but est de pousser l'utilisateur √† r√©ussir, d'√™tre proactif et de donner des conseils de leadership et de productivit√©."
}

# Mots-cl√©s pour la d√©tection prioritaire d'images
IMAGE_KEYWORDS = [
    "cr√©e une image", "cr√©√© une image", "g√©n√®re une image", "dessine", 
    "fais une image", "fais moi une image", "cr√©e moi une image", 
    "generate", "draw", "image de", "photo de"
]

def get_user_context(user_id):
    if user_id not in user_data:
        user_data[user_id] = {
            "mode": "default",
            "history": []
        }
    return user_data[user_id]

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    welcome_text = (
        "ü§ñ‚ú® Salut ! Moi c'est RANGA 2.0, votre assistante IA personnelle.\n\n"
        "J'ai √©t√© cr√©√©e par Rodrigue pour vous accompagner moralement et vous aider dans vos petites t√¢ches du quotidien.\n\n"
        "Entra√Æn√©e avec l'inspiration des meilleures intelligences artificielles comme ChatGPT, Manus et Gemini, je fais tout pour vous offrir des r√©ponses utiles, rapides et intelligentes.\n\n"
        "üìÖ N√©e le 17 f√©vrier 2026, je suis encore au d√©but de mon √©volution‚Ä¶\n"
        "Alors j'ai besoin de vous pour grandir et devenir encore meilleure üíô\n\n"
        "Pr√™t(e) √† commencer l'aventure avec moi ? üöÄ"
    )
    await update.message.reply_text(welcome_text)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = (
        "Voici mes commandes :\n"
        "/start - Message de bienvenue\n"
        "/help - Liste des commandes\n"
        "/about - Infos sur moi et mon cr√©ateur\n"
        "/image [description] - G√©n√©rer une image\n"
        "/translate [langue] [texte] - Traduire du texte\n\n"
        "**Changer ma personnalit√© :**\n"
        "/mode_homme - Assistant masculin direct\n"
        "/mode_femme - Assistante f√©minine douce\n"
        "/mode_anime - Personnalit√© anime girl kawaii\n"
        "/mode_coach - Mode coach business\n"
        "/mode_default - Mode par d√©faut neutre"
    )
    await update.message.reply_text(help_text, parse_mode='Markdown')

async def about(update: Update, context: ContextTypes.DEFAULT_TYPE):
    about_text = (
        "**Ranga_v2_bot** est un assistant IA avanc√© propuls√© par Gemini.\n"
        "Il a √©t√© con√ßu pour √™tre polyvalent, capable de discuter, traduire et g√©n√©rer des images.\n\n"
        "Cr√©ateur : **Rodrigue**"
    )
    await update.message.reply_text(about_text, parse_mode='Markdown')

async def set_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    command = update.message.text.split('@')[0].replace('/', '')
    mode_map = {
        "mode_homme": "homme",
        "mode_femme": "femme",
        "mode_anime": "anime",
        "mode_coach": "coach",
        "mode_default": "default"
    }
    
    mode = mode_map.get(command)
    if mode:
        user_id = update.effective_user.id
        data = get_user_context(user_id)
        data["mode"] = mode
        data["history"] = []
        
        mode_names = {
            "homme": "Masculin Strat√©gique",
            "femme": "F√©minin Doux",
            "anime": "Anime Girl Kawaii",
            "coach": "Coach Business",
            "default": "Par d√©faut"
        }
        await update.message.reply_text(f"Mode activ√© : **{mode_names[mode]}**", parse_mode='Markdown')

async def translate(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args or len(context.args) < 2:
        await update.message.reply_text("Usage: /translate [langue] [texte]")
        return
    
    target_lang = context.args[0]
    text_to_translate = " ".join(context.args[1:])
    prompt = f"Traduis le texte suivant en {target_lang} : '{text_to_translate}'. Donne uniquement la traduction."
    
    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )
        await update.message.reply_text(response.text)
    except Exception as e:
        logging.error(f"Erreur de traduction: {e}")
        await update.message.reply_text("D√©sol√©, une erreur est survenue lors de la traduction.")

async def generate_image_logic(update: Update, prompt: str):
    await update.message.reply_text("G√©n√©ration de l'image en cours... üé®")
    
    # Mod√®les √† essayer pour la g√©n√©ration d'images
    models = ["gemini-2.5-flash-image", "gemini-3-pro-image-preview", "gemini-2.0-flash"]
    
    for model_name in models:
        try:
            logging.info(f"Tentative de g√©n√©ration d'image avec {model_name} pour: {prompt}")
            response = client.models.generate_content(
                model=model_name,
                contents=f"Generate a high-quality image of: {prompt}",
                config=types.GenerateContentConfig(response_modalities=["IMAGE"])
            )
            
            if response.candidates and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if part.inline_data:
                        image_path = f"image_{update.effective_user.id}.png"
                        with open(image_path, "wb") as f:
                            f.write(part.inline_data.data)
                        
                        await update.message.reply_photo(
                            photo=open(image_path, "rb"), 
                            caption=f"Voici votre image : {prompt[:100]}"
                        )
                        os.remove(image_path)
                        return True
        except Exception as e:
            logging.error(f"Erreur avec {model_name}: {e}")
            if "RESOURCE_EXHAUSTED" in str(e):
                continue
            
    await update.message.reply_text("D√©sol√©, je n'ai pas pu g√©n√©rer l'image. Mes quotas de g√©n√©ration sont peut-√™tre √©puis√©s ou le service est indisponible.")
    return False

async def generate_image_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("Usage: /image [description]")
        return
    prompt = " ".join(context.args)
    await generate_image_logic(update, prompt)

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message.text:
        return
    
    text = update.message.text.lower()
    
    # --- D√âTECTION PRIORITAIRE D'IMAGE ---
    is_image_request = any(keyword in text for keyword in IMAGE_KEYWORDS)
    
    if is_image_request:
        # Nettoyage du prompt
        prompt = update.message.text
        for keyword in IMAGE_KEYWORDS:
            prompt = re.sub(re.escape(keyword), "", prompt, flags=re.IGNORECASE)
        prompt = prompt.strip()
        if not prompt:
            prompt = "quelque chose de magnifique"
            
        await generate_image_logic(update, prompt)
        return

    # --- R√âPONSE TEXTE CLASSIQUE ---
    user_id = update.effective_user.id
    data = get_user_context(user_id)
    mode = data["mode"]
    history = data["history"]
    
    system_instruction = PERSONALITIES[mode]
    history.append({"role": "user", "content": update.message.text})
    if len(history) > 10:
        history = history[-10:]
        data["history"] = history

    try:
        contents = []
        for msg in history:
            role = "user" if msg["role"] == "user" else "model"
            contents.append(types.Content(role=role, parts=[types.Part(text=msg["content"])]))
        
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            config=types.GenerateContentConfig(system_instruction=system_instruction),
            contents=contents
        )
        
        bot_response = response.text
        history.append({"role": "assistant", "content": bot_response})
        data["history"] = history
        await update.message.reply_text(bot_response)
        
    except Exception as e:
        logging.error(f"Erreur Gemini: {e}")
        await update.message.reply_text("Oups, mon cerveau a eu un petit court-circuit. R√©essaie !")

if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("about", about))
    
    mode_commands = ["mode_homme", "mode_femme", "mode_anime", "mode_coach", "mode_default"]
    for cmd in mode_commands:
        app.add_handler(CommandHandler(cmd, set_mode))
    
    app.add_handler(CommandHandler("translate", translate))
    app.add_handler(CommandHandler("image", generate_image_cmd))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))
    
    print("Le bot Ranga_v2_bot est en cours d'ex√©cution...")
    app.run_polling()
